{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3414f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 261, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/helsinki-nlp/opus-mt-en-kn/resolve/main/source.spm\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py\", line 417, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1195, in hf_hub_download\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1541, in get_hf_file_metadata\n",
      "    hf_raise_for_status(r)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 293, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-64d93e3e-460bcfdc0439eee455980424;a58b611c-ce60-4782-aa15-f8fd23bef051)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/helsinki-nlp/opus-mt-en-kn/resolve/main/source.spm.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\1170495170.py\", line 14, in translate\n",
      "    tokenizer = MarianTokenizer.from_pretrained(model_name, use_auth_token='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')\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1800, in from_pretrained\n",
      "    resolved_vocab_files[file_id] = cached_file(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py\", line 433, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: helsinki-nlp/opus-mt-en-kn is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abeeb65d311428a9034b58f6b408e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f78ef73ada460c91e262479e57658b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/1.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42476c8f9cd34277bdcc95dd97a8cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee79ab4d84e64518a8c8db8fbdb7a92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee148060f72143a1b093b82d26abc54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208e89e8ae4e466aaf79668d40392789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24af5235034745fdbc9c61e75ca0ba95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate(source_language,text, target_language):\n",
    "    language_codes = {\n",
    "        \"English\" : \"en\",\n",
    "        \"Spanish\": \"es\",\n",
    "        \"French (European)\": \"fr\",\n",
    "        \"French (Canadian)\": \"fr\",\n",
    "        \"Italian\": \"it\",\n",
    "        \"Ukrainian\": \"uk\",\n",
    "        \"Portuguese (Brazilian)\": \"pt_BR\",\n",
    "        \"Portuguese (European)\": \"pt\",\n",
    "        \"Russian\": \"ru\",\n",
    "        \"Chinese\": \"zh\",\n",
    "        \"Dutch\": \"nl\",\n",
    "        \"German\": \"de\",\n",
    "        \"Arabic\": \"ar\",\n",
    "        \"Hebrew\": \"he\",\n",
    "        \"Greek\": \"el\"\n",
    "    }\n",
    "\n",
    "    target_language_code = language_codes[target_language]\n",
    "    source_language_code = language_codes[source_language] \n",
    "    model_name = f'helsinki-nlp/opus-mt-{source_language_code}-{target_language_code}'\n",
    "    \n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67f7e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:12: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:12: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:13: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:13: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:13: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:14: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:14: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\2017634059.py:16: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs=gr.outputs.Textbox(label=\"Translated Text\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7886\n",
      "Running on public URL: https://ebbb377d7e72097d18.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ebbb377d7e72097d18.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "language_options = [\n",
    "    \"English\",\"Spanish\", \"French (European)\", \"French (Canadian)\", \"Italian\", \"Ukrainian\",\n",
    "    \"Portuguese (Brazilian)\", \"Portuguese (European)\", \"Russian\", \"Chinese\",\n",
    "    \"Dutch\", \"German\", \"Arabic\", \"Hebrew\", \"Greek\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[\n",
    "        gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
    "        gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
    "        gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
    "    ],\n",
    "    outputs=gr.outputs.Textbox(label=\"Translated Text\"),\n",
    ")\n",
    "\n",
    "iface.launch(share= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60116a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12b999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5561b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ddd2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fc41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed68cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "232632ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate(source_language,text, target_language):\n",
    "\n",
    "   \n",
    "    language_codes = {\"Afrikaans\": \"af\", \"Albanian\": \"sq\", \"Amharic\": \"am\", \"Arabic\": \"ar\", \"Armenian\": \"hy\", \"Azerbaijani\": \"az\", \"Basque\": \"eu\", \"Belarusian\": \"be\", \"Bengali\": \"bn\", \"Bosnian\": \"bs\", \"Bulgarian\": \"bg\", \"Catalan\": \"ca\", \"Cebuano\": \"ceb\", \"Chichewa\": \"ny\", \"Chinese (Simplified)\": \"zh_CN\", \"Chinese (Traditional)\": \"zh_TW\", \"Corsican\": \"co\", \"Croatian\": \"hr\", \"Czech\": \"cs\", \"Danish\": \"da\", \"Dutch\": \"nl\", \"English\": \"en\", \"Esperanto\": \"eo\", \"Estonian\": \"et\", \"Filipino\": \"tl\", \"Finnish\": \"fi\", \"French\": \"fr\", \"Frisian\": \"fy\", \"Galician\": \"gl\", \"Georgian\": \"ka\", \"German\": \"de\", \"Greek\": \"el\", \"Gujarati\": \"gu\", \"Haitian Creole\": \"ht\", \"Hausa\": \"ha\", \"Hawaiian\": \"haw\", \"Hebrew\": \"he\", \"Hindi\": \"hi\", \"Hmong\": \"hmn\", \"Hungarian\": \"hu\", \"Icelandic\": \"is\", \"Igbo\": \"ig\", \"Indonesian\": \"id\", \"Irish\": \"ga\", \"Italian\": \"it\", \"Japanese\": \"ja\", \"Javanese\": \"jv\", \"Kannada\": \"kn\", \"Kazakh\": \"kk\", \"Khmer\": \"km\", \"Kinyarwanda\": \"rw\", \"Korean\": \"ko\", \"Kurdish\": \"ku\", \"Kyrgyz\": \"ky\", \"Lao\": \"lo\", \"Latin\": \"la\", \"Latvian\": \"lv\", \"Lithuanian\": \"lt\", \"Luxembourgish\": \"lb\", \"Macedonian\": \"mk\", \"Malagasy\": \"mg\", \"Malay\": \"ms\", \"Malayalam\": \"ml\", \"Maltese\": \"mt\", \"Maori\": \"mi\", \"Marathi\": \"mr\", \"Mongolian\": \"mn\", \"Myanmar (Burmese)\": \"my\", \"Nepali\": \"ne\", \"Norwegian\": \"no\", \"Odia (Oriya)\": \"or\", \"Pashto\": \"ps\", \"Persian\": \"fa\", \"Polish\": \"pl\", \"Portuguese\": \"pt\", \"Punjabi\": \"pa\", \"Romanian\": \"ro\", \"Russian\": \"ru\", \"Samoan\": \"sm\", \"Scots Gaelic\": \"gd\", \"Serbian\": \"sr\", \"Sesotho\": \"st\", \"Shona\": \"sn\", \"Sindhi\": \"sd\", \"Sinhala\": \"si\", \"Slovak\": \"sk\", \"Slovenian\": \"sl\", \"Somali\": \"so\", \"Spanish\": \"es\", \"Sundanese\": \"su\", \"Swahili\": \"sw\", \"Swedish\": \"sv\", \"Tajik\": \"tg\", \"Tamil\": \"ta\", \"Tatar\": \"tt\", \"Telugu\": \"te\", \"Thai\": \"th\", \"Turkish\": \"tr\", \"Turkmen\": \"tk\", \"Ukrainian\": \"uk\", \"Urdu\": \"ur\", \"Uyghur\": \"ug\", \"Uzbek\": \"uz\", \"Vietnamese\": \"vi\", \"Welsh\": \"cy\", \"Xhosa\": \"xh\", \"Yiddish\": \"yi\", \"Yoruba\": \"yo\", \"Zulu\": \"zu\"}\n",
    "\n",
    "    #token= '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'\n",
    "    target_language_code = language_codes[target_language]\n",
    "    source_language_code = language_codes[source_language] \n",
    "    model_name = f'helsinki-nlp/opus-mt-{source_language_code}-{target_language_code}'\n",
    "    \n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name, use_auth_token='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')\n",
    "    model = MarianMTModel.from_pretrained(model_name, use_auth_token= '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')\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "811a1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:22: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:22: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:23: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:23: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:23: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:24: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:24: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\3817920783.py:26: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs=gr.outputs.Textbox(label=\"Translated Text\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7888\n",
      "Running on public URL: https://377330c5c7cdad24aa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://377330c5c7cdad24aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 261, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/helsinki-nlp/opus-mt-en-te/resolve/main/source.spm\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py\", line 417, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1195, in hf_hub_download\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1541, in get_hf_file_metadata\n",
      "    hf_raise_for_status(r)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 293, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-64d93aa3-0dd572d71dec841373d9a4e1;363b5386-2c6f-490a-a2b9-261ffa6be899)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/helsinki-nlp/opus-mt-en-te/resolve/main/source.spm.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\gradio\\utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_14896\\1170495170.py\", line 14, in translate\n",
      "    tokenizer = MarianTokenizer.from_pretrained(model_name, use_auth_token='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')\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1800, in from_pretrained\n",
      "    resolved_vocab_files[file_id] = cached_file(\n",
      "  File \"C:\\Users\\nandi\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py\", line 433, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: helsinki-nlp/opus-mt-en-te is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fd88d756a048fe8f138d30a8574a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30caf6cba0e04739af4cbe56ad93d0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/756k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a23d6650aa947b6aea6e8b48c01ff13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ed2aaf219742aab920ce84ac3dc1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38c273de56742bca2409a94ead6ad2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b60d2eac0d44c082258160410be4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/289M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264d9f21b350448f812f81dda00bcd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_options = [\"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Azerbaijani\",\n",
    "            \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Bulgarian\", \"Catalan\",\n",
    "            \"Cebuano\", \"Chichewa\", \"Chinese (Simplified)\", \"Chinese (Traditional)\",\n",
    "            \"Corsican\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Esperanto\",\n",
    "            \"Estonian\", \"Filipino\", \"Finnish\", \"French\", \"Frisian\", \"Galician\", \"Georgian\",\n",
    "            \"German\", \"Greek\", \"Gujarati\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\",\n",
    "            \"Hindi\", \"Hmong\", \"Hungarian\", \"Icelandic\", \"Igbo\", \"Indonesian\", \"Irish\",\n",
    "            \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Kinyarwanda\",\n",
    "            \"Korean\", \"Kurdish\", \"Kyrgyz\", \"Lao\", \"Latin\", \"Latvian\", \"Lithuanian\",\n",
    "            \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\",\n",
    "            \"Maori\", \"Marathi\", \"Mongolian\", \"Myanmar (Burmese)\", \"Nepali\", \"Norwegian\",\n",
    "            \"Odia (Oriya)\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Romanian\",\n",
    "            \"Russian\", \"Samoan\", \"Scots Gaelic\", \"Serbian\", \"Sesotho\", \"Shona\", \"Sindhi\",\n",
    "            \"Sinhala\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\",\n",
    "            \"Swedish\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Turkish\", \"Turkmen\",\n",
    "            \"Ukrainian\", \"Urdu\", \"Uyghur\", \"Uzbek\", \"Vietnamese\", \"Welsh\", \"Xhosa\",\n",
    "            \"Yiddish\", \"Yoruba\", \"Zulu\"]\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[\n",
    "        gr.inputs.Dropdown(choices=language_options, label=\"Source Language\"),\n",
    "        gr.inputs.Textbox(lines=10, label=\"Enter text to translate:\"),\n",
    "        gr.inputs.Dropdown(choices=language_options, label=\"Target Language\"),\n",
    "    ],\n",
    "    outputs=gr.outputs.Textbox(label=\"Translated Text\"),\n",
    ")\n",
    "\n",
    "iface.launch(share= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_options = [\n",
    "    \"English\",\"Spanish\", \"French (European)\", \"French (Canadian)\", \"Italian\", \"Ukrainian\",\n",
    "    \"Portuguese (Brazilian)\", \"Portuguese (European)\", \"Russian\", \"Chinese\",\n",
    "    \"Dutch\", \"German\", \"Arabic\", \"Hebrew\", \"Greek\",\n",
    "    \n",
    "]\n",
    "\n",
    "    language_codes = {\n",
    "        \"English\" : \"en\",\n",
    "        \"Spanish\": \"es\",\n",
    "        \"French (European)\": \"fr\",\n",
    "        \"French (Canadian)\": \"fr\",\n",
    "        \"Italian\": \"it\",\n",
    "        \"Ukrainian\": \"uk\",\n",
    "        \"Portuguese (Brazilian)\": \"pt_BR\",\n",
    "        \"Portuguese (European)\": \"pt\",\n",
    "        \"Russian\": \"ru\",\n",
    "        \"Chinese\": \"zh\",\n",
    "        \"Dutch\": \"nl\",\n",
    "        \"German\": \"de\",\n",
    "        \"Arabic\": \"ar\",\n",
    "        \"Hebrew\": \"he\",\n",
    "        \"Greek\": \"el\"\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
